Got it! Here's the revised `README.md`, updated to reflect **support for any number of configurable AI models**, with a dynamic voting/judging system where **each AI evaluates all the others**.

---

````markdown
# AI Council CLI

**AI Council** is a terminal-based AI assistant that leverages the collective intelligence of multiple large language models to deliver high-quality answers and code suggestions through democratic consensus.

Rather than relying on a single model, AI Council queries **any number of configurable AIs in parallel**â€”such as Claude, ChatGPT, DeepSeek, Mistral, etc.â€”then asks **each model to judge the others' responses**, scoring them based on quality. The best response is selected through rank-based voting and presented to the user for approval or refinement.

## ğŸ§  Key Features

- ğŸ§¾ **Chat-style CLI interface** â€“ Ask natural language questions and receive clear, contextual responses.
- ğŸ¤– **Multi-model orchestration** â€“ Supports an arbitrary number of AI models, configured in one place.
- âš–ï¸ **Decentralized peer review** â€“ Each AI agent ranks the othersâ€™ solutions.
- ğŸ† **Ranked-choice voting** â€“ Uses rank voting (e.g., Borda count) to determine the winner.
- ğŸ” **Human-in-the-loop refinement** â€“ Accept, reject, or iterate on the winning result.
- ğŸ§± **Modular model adapters** â€“ Easily add/remove AI backends (Claude, GPT-4, Ollama, etc.).

---

## ğŸ”§ Supported AI Backends

Out of the box, AI Council supports:

- ğŸ§  **Claude** (Anthropic API)
- ğŸ’¬ **ChatGPT** (OpenAI API)
- ğŸ§° **DeepSeek Coder** (via [Ollama](https://ollama.com))
- ğŸ§ª ...and any other model via plugin-style adapter.

---

## ğŸ—ï¸ Planned Architecture

```text
+--------------------------+
|      AI Model Agents     |
| (Configured dynamically) |
+------------+-------------+
             |
             v
+----------------------------+
|  Prompt Dispatcher         |
| - Sends user prompt to all |
|   configured models        |
+----------------------------+
             |
             v
+----------------------------+
|  Peer Judging System      |
| - Each model ranks the    |
|   responses of all others |
+----------------------------+
             |
             v
+----------------------------+
|  Rank Voting Aggregator   |
| - Scores models based on  |
|   peer rankings           |
| - Picks the winner        |
+----------------------------+
             |
             v
+----------------------------+
|  Terminal Interaction UI  |
| - Shows result            |
| - Accept / Reject / Refine|
+----------------------------+
````

---

## âœ¨ Example Workflow

```bash
$ aicouncil ask "Refactor this React component to use hooks instead of a class..."

ğŸ¤– Claude is thinking...
ğŸ¤– ChatGPT is thinking...
ğŸ¤– DeepSeek is thinking...
ğŸ¤– Mistral is thinking...

ğŸ Peer Reviews Complete:

Claude ranked: 1. ChatGPT, 2. DeepSeek, 3. Mistral  
ChatGPT ranked: 1. Claude, 2. Mistral, 3. DeepSeek  
DeepSeek ranked: 1. Claude, 2. ChatGPT, 3. Mistral  
Mistral ranked: 1. Claude, 2. ChatGPT, 3. DeepSeek

ğŸ† Final Winner: **Claudeâ€™s response**

--- Claudeâ€™s Suggested Code ---
[...code block...]

Do you want to:
[A] Accept  [F] Provide Feedback  [R] Rerun Round
```

---

## ğŸ“¦ Project Structure (Planned)

```text
aicouncil/
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ claude.py
â”‚   â”œâ”€â”€ chatgpt.py
â”‚   â”œâ”€â”€ deepseek.py
â”‚   â””â”€â”€ mistral.py  # Example custom model
â”œâ”€â”€ config/
â”‚   â””â”€â”€ models.yaml  # List of enabled models + credentials
â”œâ”€â”€ judge.py         # Prompts each model to rank the others
â”œâ”€â”€ rank_voting.py   # Borda count or Condorcet-style vote logic
â”œâ”€â”€ cli.py           # Terminal interface
â”œâ”€â”€ session_history/
â”‚   â””â”€â”€ ... (logs and feedback)
â”œâ”€â”€ utils.py
â””â”€â”€ main.py
```

---

## ğŸ”§ Setup (Planned)

### Requirements

* Python 3.10+
* Pipenv or virtualenv
* API Keys for the models you enable
* Ollama (for any local models like DeepSeek or Mistral)

### Clone & Setup

```bash
git clone https://github.com/YOUR_USERNAME/aicouncil.git
cd aicouncil
pip install -r requirements.txt
```

### Configure Models

Create `config/models.yaml` like this:

```yaml
models:
  - name: claude
    adapter: claude
    api_key: ${ANTHROPIC_API_KEY}

  - name: chatgpt
    adapter: chatgpt
    api_key: ${OPENAI_API_KEY}

  - name: deepseek
    adapter: ollama
    local_name: deepseek-coder

  - name: mistral
    adapter: ollama
    local_name: mistral
```

You can comment out any model to disable it.

---

## ğŸ—³ï¸ Voting Logic

Uses **Borda count** by default:

* Each model ranks the others.
* Scores assigned as:

  * 1st = N-1 points
  * 2nd = N-2 points
  * ...
  * Last = 0 points
* The model with the **highest total score wins**.

You could later switch to:

* **Condorcet**
* **Plurality**
* **Weighted judge voting**

---

## ğŸ™‹â€â™€ï¸ Contributing

Weâ€™re looking for contributors passionate about:

* AI orchestration and meta-model coordination
* CLI developer productivity tools
* Transparent and ethical model comparison

---

## ğŸ“„ License

MIT

---

## ğŸ’¡ Inspiration

This project is inspired by the belief that **no single AI is perfect**. By enabling them to **peer-review and vote on each other's output**, we combine their strengths into a single, intelligent, trustworthy assistantâ€”**an AI council**.

---

```

Let me know if you'd like this turned into a real repository structure or if you'd like help with a `models.yaml` parser or a CLI prototype to go with it!
```
